# Deep Unsupervised Learning using Nonequilibrium Thermodynamics



核心思想: 通过一个迭代的前向扩散过程,缓慢的扰乱数据集分布的结构; 学习一个反向的扩散过程, 恢复数据的结构,得到一个具有很高灵活性和容易处理的生成模型



概率模型两个相互冲突的目标: 容易处理; 灵活性. 容易处理的特性使得模型的解释性和对数据的拟合非常好,但是很难迁移到结构更复杂的数据集上.灵活的模型可以拟合复杂的模型,但是模型的处理很复杂, 论文中列举了一个例子, 概率分布的正则常量通常是难以计算的.

列举了为了解决这两个相互冲突的目标的关于近似方法的研究, 都是在二者上做折中.

作者提出一种新的定义概率模型的方法, 优势:

1.   在模型结构上非常灵活
2.   采样准确
3.   和其它概率分布容易相乘(为了计算后验)?
4.   模型的对数似然和每个状态的概率很容易计算

主要思路:使用一个马尔科夫链逐步将一个分布变为另外一个分布, 使用扩散过程构建一个生成马尔科夫链来将一个简单已知的概率分布变为数据的概率分布.

在相关工作中提及了此前的变分学习和推理算法, 后面突出提出的方法和此前变分方法的不同:

1.   采样是通过退火而不是变分贝叶斯;
2.    学到的分布和其它概率分布相乘非常容易(比如计算后验等)??
3.   解决变分推理方法训练的一些问题,主要是推理和生成部分的不对成
4.   训练模型的规模更大, 数百层
5.   每一层产生的熵的上限和下限







